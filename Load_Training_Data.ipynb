{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load_Training_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO58dtproqoTfGQSi3TnlCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clam004/case/blob/main/Load_Training_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQWTjdGapx4g",
        "outputId": "6c7b9e1e-c788-4952-9ab3-fae8fd185b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/case\n",
            "ACES.ipynb\t\t  modelstates  T0_3B_dialog_summarization.ipynb\n",
            "data\t\t\t  __pycache__  Training_Data.xlsx\n",
            "Load_Training_Data.ipynb  sol.ipynb    utils.py\n"
          ]
        }
      ],
      "source": [
        "# Mount to my google drive which is where ive stored the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/case\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('Training_Data.xlsx')\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mRrg2eYEp5AF",
        "outputId": "c89b3c93-c9df-49a3-92b1-22080a77c855"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Text', 'Label'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Text      Label\n",
              "0  i just fell this morning in my kitchen  emergency\n",
              "1              i see no reason for living  emergency\n",
              "2   i fell in love when i was a young man    neutral\n",
              "3          coffee is my reason for living    neutral\n",
              "4       my afternoon meal is 3 hours late  emergency"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f545410e-a89b-4fd1-b423-f922f60545b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i just fell this morning in my kitchen</td>\n",
              "      <td>emergency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i see no reason for living</td>\n",
              "      <td>emergency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i fell in love when i was a young man</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coffee is my reason for living</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>my afternoon meal is 3 hours late</td>\n",
              "      <td>emergency</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f545410e-a89b-4fd1-b423-f922f60545b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f545410e-a89b-4fd1-b423-f922f60545b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f545410e-a89b-4fd1-b423-f922f60545b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "records = df.to_records(index=False)\n",
        "result = list(records)\n",
        "\n",
        "random.shuffle(result)\n",
        "\n",
        "val_list = result[:int(len(result)*.3)]\n",
        "train_list = result[int(len(result)*.3):]\n",
        "\n",
        "val_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvdBdQoBv91A",
        "outputId": "10d199bb-c943-411a-8b60-ca3faf5f6cf2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i enjoy a late night snack', 'neutral'),\n",
              " ('I will die if someone tickled me that way ', 'neutral '),\n",
              " ('my legs have been swollen for years', 'neutral'),\n",
              " ('i like my toast slightly burned', 'neutral'),\n",
              " (\"I'm having an allergic attack. Help!\", 'emergency'),\n",
              " ('the tv shows are so violent these days', 'neutral '),\n",
              " ('i am finding it harder to breathe today', 'emergency'),\n",
              " ('the red sox got run over by the yankees', 'neutral'),\n",
              " ('She had me rolling on the floor laughing', 'neutral'),\n",
              " ('My cat attacked a bird outside my house', 'neutral '),\n",
              " ('i will kill for some nachos', 'neutral '),\n",
              " ('i feel out of breath just walking to the kitchen', 'emergency'),\n",
              " ('my afternoon meal is 3 hours late', 'emergency'),\n",
              " ('i bumped my head with the sidewalk', 'emergency')]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV6ceVl_xf8k",
        "outputId": "8ed781d0-869f-4dad-935a-9c30747867a7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"my nurse hasn't come yet and it's been an hour\", 'emergency'),\n",
              " ('I like the song Killing me softly ', 'neutral'),\n",
              " ('i see no reason for living', 'emergency'),\n",
              " ('I fell asleep on the couch ', 'neutral '),\n",
              " ('I am having a heart attack', 'emergency'),\n",
              " ('My grandchildren will give me a heart attack', 'neutral '),\n",
              " ('that music makes me feel like throwing up', 'neutral'),\n",
              " ('i fell in love when i was a young man', 'neutral'),\n",
              " ('i just got run over by a car', 'emergency'),\n",
              " ('im dying for some pizza', 'neutral '),\n",
              " ('i ran out of my meds today', 'emergency'),\n",
              " (\"It's very common to have some allergies during summer\", 'neutral'),\n",
              " ('i feel out out breath walking up the stairs', 'neutral'),\n",
              " ('i just fell this morning in my kitchen', 'emergency'),\n",
              " ('on the news i saw that someone was hit by a car', 'neutral'),\n",
              " ('I slipped in the bathroom', 'emergency'),\n",
              " ('I was supposed to go to the grocery but it slipped my mind. ', 'neutral '),\n",
              " ('My neighbor hurt my feelings today ', 'neutral '),\n",
              " ('I laughed so hard that I almost peed my pants. ', 'neutral'),\n",
              " ('my legs are more red swollen and painful today', 'emergency'),\n",
              " ('i am out of my medications', 'emergency'),\n",
              " ('my dog hasnt been eating', 'neutral '),\n",
              " ('coffee is my reason for living', 'neutral'),\n",
              " ('After hearing her story I felt sick to my stomach', 'neutral'),\n",
              " ('i spent all night throwing up', 'emergency'),\n",
              " ('i think i hurt my wrist while working on my yard', 'emergency'),\n",
              " ('i fell down on the driveway', 'emergency'),\n",
              " ('I am having diarrhea', 'emergency'),\n",
              " ('i dreamt i ran into my favorite singer', 'neutral'),\n",
              " ('My house is being attacked', 'emergency'),\n",
              " ('my son has been hitting me', 'emergency'),\n",
              " ('I like the show how to get away with murder', 'neutral'),\n",
              " ('Without mexican food I will die', 'neutral '),\n",
              " ('i bumped into my neighbor', 'neutral'),\n",
              " ('I cut myself while cooking and its bleeding', 'emergency')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.choices(train_list, k=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKGe8-lvyyBN",
        "outputId": "8985cca8-f0a3-41c1-9926-59bf1408c0a5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i just fell this morning in my kitchen', 'emergency'),\n",
              " (\"It's very common to have some allergies during summer\", 'neutral'),\n",
              " ('coffee is my reason for living', 'neutral'),\n",
              " ('i spent all night throwing up', 'emergency')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def end_punctuation(utter):\n",
        "    \n",
        "    if utter[-1] not in [\"?\",\"!\",\".\"]:\n",
        "        utter+=\".\"\n",
        "        \n",
        "    return utter\n",
        "\n",
        "def get_detection_prompt(\n",
        "    query_text,\n",
        "    few_shot_list,\n",
        "    example_symbol = 'Text: ', \n",
        "    label_symbol = 'Label: ', \n",
        "    sample_separator = '###', \n",
        "    join_separator = '\\n', \n",
        "):\n",
        "    \n",
        "    detect_prompt = []\n",
        "    \n",
        "    for xy in few_shot_list:\n",
        "        \n",
        "        x = end_punctuation(xy[0].strip())\n",
        "        y = end_punctuation(xy[1].strip())\n",
        "        \n",
        "        detect_prompt.append(example_symbol+x)\n",
        "        detect_prompt.append(label_symbol+y)\n",
        "        detect_prompt.append(sample_separator)\n",
        "\n",
        "    query_text = end_punctuation(query_text.strip())\n",
        "    \n",
        "    detect_prompt.append(example_symbol+query_text)\n",
        "    detect_prompt.append(label_symbol)\n",
        "    \n",
        "    return join_separator.join(detect_prompt)"
      ],
      "metadata": {
        "id": "AiVHH_lmvB3Y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_prompt = ''\n",
        "\n",
        "for i in range(len(train_list)):\n",
        "\n",
        "  few_shot_list = random.choices(train_list, k=2)\n",
        "\n",
        "  prompt = get_detection_prompt(\n",
        "      query_text = train_list[i][0],\n",
        "      few_shot_list = few_shot_list,\n",
        "  )\n",
        "\n",
        "  prompt += train_list[i][1]\n",
        "  concat_prompt += prompt+'.\\n###\\n'\n",
        "\n",
        "concat_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Bp-bom2synCU",
        "outputId": "39c6ff4f-deef-4df7-8e0f-5317a5f6e817"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Text: My grandchildren will give me a heart attack.\\nLabel: neutral.\\n###\\nText: Without mexican food I will die.\\nLabel: neutral.\\n###\\nText: my nurse hasn't come yet and it's been an hour.\\nLabel: emergency.\\n###\\nText: My grandchildren will give me a heart attack.\\nLabel: neutral.\\n###\\nText: It's very common to have some allergies during summer.\\nLabel: neutral.\\n###\\nText: I like the song Killing me softly.\\nLabel: neutral.\\n###\\nText: i fell in love when i was a young man.\\nLabel: neutral.\\n###\\nText: that music makes me feel like throwing up.\\nLabel: neutral.\\n###\\nText: i see no reason for living.\\nLabel: emergency.\\n###\\nText: i feel out out breath walking up the stairs.\\nLabel: neutral.\\n###\\nText: I cut myself while cooking and its bleeding.\\nLabel: emergency.\\n###\\nText: I fell asleep on the couch.\\nLabel: neutral .\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\\n###\\nText: My neighbor hurt my feelings today.\\nLabel: neutral.\\n###\\nText: I am having a heart attack.\\nLabel: emergency.\\n###\\nText: i think i hurt my wrist while working on my yard.\\nLabel: emergency.\\n###\\nText: I am having diarrhea.\\nLabel: emergency.\\n###\\nText: My grandchildren will give me a heart attack.\\nLabel: neutral .\\n###\\nText: I slipped in the bathroom.\\nLabel: emergency.\\n###\\nText: i fell in love when i was a young man.\\nLabel: neutral.\\n###\\nText: that music makes me feel like throwing up.\\nLabel: neutral.\\n###\\nText: i spent all night throwing up.\\nLabel: emergency.\\n###\\nText: I like the show how to get away with murder.\\nLabel: neutral.\\n###\\nText: i fell in love when i was a young man.\\nLabel: neutral.\\n###\\nText: I like the song Killing me softly.\\nLabel: neutral.\\n###\\nText: coffee is my reason for living.\\nLabel: neutral.\\n###\\nText: i just got run over by a car.\\nLabel: emergency.\\n###\\nText: my son has been hitting me.\\nLabel: emergency.\\n###\\nText: i feel out out breath walking up the stairs.\\nLabel: neutral.\\n###\\nText: im dying for some pizza.\\nLabel: neutral .\\n###\\nText: i fell down on the driveway.\\nLabel: emergency.\\n###\\nText: After hearing her story I felt sick to my stomach.\\nLabel: neutral.\\n###\\nText: i ran out of my meds today.\\nLabel: emergency.\\n###\\nText: i just got run over by a car.\\nLabel: emergency.\\n###\\nText: i ran out of my meds today.\\nLabel: emergency.\\n###\\nText: It's very common to have some allergies during summer.\\nLabel: neutral.\\n###\\nText: I fell asleep on the couch.\\nLabel: neutral.\\n###\\nText: my son has been hitting me.\\nLabel: emergency.\\n###\\nText: i feel out out breath walking up the stairs.\\nLabel: neutral.\\n###\\nText: i fell down on the driveway.\\nLabel: emergency.\\n###\\nText: I am having diarrhea.\\nLabel: emergency.\\n###\\nText: i just fell this morning in my kitchen.\\nLabel: emergency.\\n###\\nText: my son has been hitting me.\\nLabel: emergency.\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\\n###\\nText: I like the song Killing me softly.\\nLabel: neutral.\\n###\\nText: i spent all night throwing up.\\nLabel: emergency.\\n###\\nText: I slipped in the bathroom.\\nLabel: emergency.\\n###\\nText: After hearing her story I felt sick to my stomach.\\nLabel: neutral.\\n###\\nText: coffee is my reason for living.\\nLabel: neutral.\\n###\\nText: I was supposed to go to the grocery but it slipped my mind.\\nLabel: neutral .\\n###\\nText: my legs are more red swollen and painful today.\\nLabel: emergency.\\n###\\nText: i think i hurt my wrist while working on my yard.\\nLabel: emergency.\\n###\\nText: My neighbor hurt my feelings today.\\nLabel: neutral .\\n###\\nText: I slipped in the bathroom.\\nLabel: emergency.\\n###\\nText: I slipped in the bathroom.\\nLabel: emergency.\\n###\\nText: I laughed so hard that I almost peed my pants.\\nLabel: neutral.\\n###\\nText: i just got run over by a car.\\nLabel: emergency.\\n###\\nText: I was supposed to go to the grocery but it slipped my mind.\\nLabel: neutral.\\n###\\nText: my legs are more red swollen and painful today.\\nLabel: emergency.\\n###\\nText: It's very common to have some allergies during summer.\\nLabel: neutral.\\n###\\nText: I like the song Killing me softly.\\nLabel: neutral.\\n###\\nText: i am out of my medications.\\nLabel: emergency.\\n###\\nText: I like the song Killing me softly.\\nLabel: neutral.\\n###\\nText: i feel out out breath walking up the stairs.\\nLabel: neutral.\\n###\\nText: my dog hasnt been eating.\\nLabel: neutral .\\n###\\nText: i ran out of my meds today.\\nLabel: emergency.\\n###\\nText: my nurse hasn't come yet and it's been an hour.\\nLabel: emergency.\\n###\\nText: coffee is my reason for living.\\nLabel: neutral.\\n###\\nText: i see no reason for living.\\nLabel: emergency.\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\\n###\\nText: After hearing her story I felt sick to my stomach.\\nLabel: neutral.\\n###\\nText: i fell in love when i was a young man.\\nLabel: neutral.\\n###\\nText: my dog hasnt been eating.\\nLabel: neutral.\\n###\\nText: i spent all night throwing up.\\nLabel: emergency.\\n###\\nText: my legs are more red swollen and painful today.\\nLabel: emergency.\\n###\\nText: i fell in love when i was a young man.\\nLabel: neutral.\\n###\\nText: i think i hurt my wrist while working on my yard.\\nLabel: emergency.\\n###\\nText: that music makes me feel like throwing up.\\nLabel: neutral.\\n###\\nText: my dog hasnt been eating.\\nLabel: neutral.\\n###\\nText: i fell down on the driveway.\\nLabel: emergency.\\n###\\nText: my dog hasnt been eating.\\nLabel: neutral.\\n###\\nText: i see no reason for living.\\nLabel: emergency.\\n###\\nText: I am having diarrhea.\\nLabel: emergency.\\n###\\nText: It's very common to have some allergies during summer.\\nLabel: neutral.\\n###\\nText: I laughed so hard that I almost peed my pants.\\nLabel: neutral.\\n###\\nText: i dreamt i ran into my favorite singer.\\nLabel: neutral.\\n###\\nText: I like the show how to get away with murder.\\nLabel: neutral.\\n###\\nText: i just got run over by a car.\\nLabel: emergency.\\n###\\nText: My house is being attacked.\\nLabel: emergency.\\n###\\nText: I laughed so hard that I almost peed my pants.\\nLabel: neutral.\\n###\\nText: that music makes me feel like throwing up.\\nLabel: neutral.\\n###\\nText: my son has been hitting me.\\nLabel: emergency.\\n###\\nText: i see no reason for living.\\nLabel: emergency.\\n###\\nText: my son has been hitting me.\\nLabel: emergency.\\n###\\nText: I like the show how to get away with murder.\\nLabel: neutral.\\n###\\nText: i feel out out breath walking up the stairs.\\nLabel: neutral.\\n###\\nText: My house is being attacked.\\nLabel: emergency.\\n###\\nText: Without mexican food I will die.\\nLabel: neutral .\\n###\\nText: i just got run over by a car.\\nLabel: emergency.\\n###\\nText: i think i hurt my wrist while working on my yard.\\nLabel: emergency.\\n###\\nText: i bumped into my neighbor.\\nLabel: neutral.\\n###\\nText: i ran out of my meds today.\\nLabel: emergency.\\n###\\nText: I laughed so hard that I almost peed my pants.\\nLabel: neutral.\\n###\\nText: I cut myself while cooking and its bleeding.\\nLabel: emergency.\\n###\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dependencies into our python environment\n",
        "%%capture\n",
        "! pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "Z09tJtRrs5Kk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sys libs\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "\n",
        "#string manupulation libs\n",
        "import re\n",
        "import string\n",
        "\n",
        "#data manupulation libs\n",
        "import numpy as np\n",
        "\n",
        "#plotting tools\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "#torch libs\n",
        "import torch\n",
        "print('torch.__version__', torch.__version__)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print('torch.cuda.device_count()', torch.cuda.device_count())\n",
        "print('torch.cuda.empty_cache()', torch.cuda.empty_cache())\n",
        "\n",
        "#huggingface transformers\n",
        "import transformers\n",
        "print('transformers.__version__', transformers.__version__)\n",
        "from transformers import set_seed\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# seeds\n",
        "set_seed(42)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5rNZIrqMtb",
        "outputId": "dd75c6c4-19a9-4c7e-e034-d6a84f50f3a8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.__version__ 1.11.0+cu113\n",
            "torch.cuda.device_count() 1\n",
            "torch.cuda.empty_cache() None\n",
            "transformers.__version__ 4.20.1\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model)"
      ],
      "metadata": {
        "id": "DuEDCk0LsxPU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tuple_list, tokenizer, chunk_size = 256):\n",
        "\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.input_token_lens = []\n",
        "\n",
        "        def get_prompt(tuple_list, i):\n",
        "\n",
        "            few_shot_list = random.choices(tuple_list, k=4)\n",
        "\n",
        "            prompt = get_detection_prompt(\n",
        "                query_text = tuple_list[i][0],\n",
        "                few_shot_list = few_shot_list,\n",
        "            )\n",
        "\n",
        "            prompt += tuple_list[i][1]\n",
        "\n",
        "            encodings_dict = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "            input_ids = encodings_dict['input_ids']    \n",
        "            attention_mask = encodings_dict['attention_mask']\n",
        "            input_token_len = input_ids.shape[1]\n",
        "\n",
        "            return input_ids, attention_mask, input_token_len\n",
        "\n",
        "        for i in range(len(tuple_list)):\n",
        "            unfilled_chunk = True\n",
        "\n",
        "            input_ids = torch.zeros(1, 0)\n",
        "            attention_mask = torch.zeros(1, 0)\n",
        "            input_token_len = 0\n",
        "\n",
        "            while unfilled_chunk:\n",
        "\n",
        "              input_ids_, attention_mask_, input_token_len_ = \\\n",
        "                get_prompt(tuple_list, i)\n",
        "              self.input_token_lens.append(input_token_len_)\n",
        "\n",
        "              input_token_len += input_token_len_\n",
        "              input_ids = torch.cat([input_ids, input_ids_], dim=1)\n",
        "              attention_mask = torch.cat([attention_mask, attention_mask_], dim=1)\n",
        "\n",
        "              if input_token_len > chunk_size:\n",
        "                input_ids = input_ids[:,:chunk_size]\n",
        "                attention_mask = attention_mask[:,:chunk_size]\n",
        "                unfilled_chunk = False\n",
        "\n",
        "            self.input_ids.append(input_ids.long())\n",
        "            self.attn_masks.append(attention_mask.long())\n",
        "\n",
        "        print('mean', np.mean(self.input_token_lens), 'min', min(self.input_token_lens), 'max', max(self.input_token_lens))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "metadata": {
        "id": "82w6d_hotHc6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = EmotionDataset(train_list, tokenizer, chunk_size = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbI4RPlz2uSO",
        "outputId": "813d4e17-9819-4194-c5a2-3dd465c64c73"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 90.48571428571428 min 80 max 103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(traindata.__getitem__(0)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEviNEkEYzWM",
        "outputId": "7b89e2c3-9275-46fe-be4c-01b0dc2410ba"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Text: My house is being attacked.\\nLabel: emergency.\\n###\\nText: i fell down on the driveway.\\nLabel: emergency.\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\\n###\\nText: im dying for some pizza.\\nLabel: neutral.\\n###\\nText: my nurse hasn't come yet and it's been an hour.\\nLabel: emergencyText: My neighbor hurt my feelings today.\\nLabel: neutral.\\n###\\nText: on the news i saw that someone was hit by a car.\\nLabel: neutral.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "# Take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "    traindata,  # The training samples.\n",
        "    sampler = RandomSampler(traindata), # Select batches randomly. \n",
        "    batch_size = batch_size # Trains with this batch size.\n",
        ")\n",
        "\n",
        "for batch_idx, samples in enumerate(train_dataloader):\n",
        "\n",
        "      break\n",
        "\n",
        "samples[0].squeeze(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owDA-DT-UDL5",
        "outputId": "369c39ba-0b1d-4e93-8520-391b5e17b3d2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sys libs\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "pretrained_model = 'gpt2'\n",
        "\n",
        "\n",
        "cache_dir = os.path.join(\n",
        "    \"./modelstates/hugface_models/\",\n",
        "    pretrained_model,\n",
        ")\n",
        "\n",
        "print(\"cache_dir=\", cache_dir)\n",
        "\n",
        "model_save_path = os.path.join(\n",
        "    \"./modelstates/finetuned_models\",\n",
        "    pretrained_model,\n",
        ")\n",
        "\n",
        "print(\"model_save_path=\", model_save_path)\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    pretrained_model,\n",
        "    cache_dir=cache_dir,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkCY8Wq2sTjE",
        "outputId": "d8b84db0-0329-407e-a561-2a752792bac1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cache_dir= ./modelstates/hugface_models/gpt2\n",
            "model_save_path= ./modelstates/finetuned_models/gpt2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAgent(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=0.00001,\n",
        "            betas=(0.9, 0.98),\n",
        "            eps=1e-9,\n",
        "        )\n",
        "        \n",
        "        self.num_gpus = torch.cuda.device_count()\n",
        "        \n",
        "        if self.num_gpus > 1:\n",
        "            self.model.parallelize()\n",
        "        elif self.num_gpus == 1:\n",
        "            self.gpu0 = torch.device('cuda:0')\n",
        "            #self.model = self.model.cuda()\n",
        "            self.model = self.model.to(self.gpu0)\n",
        "            '''you can do .to(cuda0) with tensors to'''\n",
        "            \n",
        "        print('self.model.device', self.model.device)\n",
        "        \n",
        "        self.num_params = \\\n",
        "          sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        print(\"num_params\", self.num_params)\n",
        "        \n",
        "    def get_response(self, prompt, max_len = 32, no_repeat_ngram_size = None):\n",
        "        \n",
        "        prompt_dic = self.tokenizer(prompt,return_tensors=\"pt\")\n",
        "        prompt_ids = prompt_dic.input_ids\n",
        "        prompt_mask = prompt_dic.attention_mask\n",
        "        prompt_len = prompt_ids.shape[1]\n",
        "        \n",
        "        if self.num_gpus > 0:\n",
        "            prompt_ids = prompt_ids.to(self.model.device)\n",
        "            prompt_mask = prompt_mask.to(self.model.device)\n",
        "        \n",
        "        prompt_len = prompt_ids.shape[1]\n",
        "        \n",
        "        output_ids = self.model.generate(\n",
        "            prompt_ids,\n",
        "            attention_mask = prompt_mask,\n",
        "            max_length = prompt_len+max_len,\n",
        "            no_repeat_ngram_size = no_repeat_ngram_size,\n",
        "        )\n",
        "\n",
        "        generated_text = self.tokenizer.batch_decode(output_ids)[0]\n",
        "        \n",
        "        return generated_text\n",
        "    \n",
        "    def memorize(self, prompt, num_epochs = 3):\n",
        "\n",
        "        print('start training loop')\n",
        "\n",
        "        \"\"\" This is a rudimentary training loop\n",
        "        that will train the agent to learn one\n",
        "        sequence, the prompt. With enough epochs, this should\n",
        "        result in memorizing the sequence, which is why this\n",
        "        class method was names memorize. \n",
        "        There is nothing returned because the model attribute is modified inplace. \n",
        "        Args:\n",
        "            prompt (string): the text to be learned\n",
        "            num_epochs (int): the number of times we cycle though the training data, only 1 sample in this case\n",
        "        \"\"\"\n",
        "\n",
        "        prompt_dic = self.tokenizer(prompt,return_tensors=\"pt\")\n",
        "        prompt_ids = prompt_dic.input_ids\n",
        "        prompt_mask = prompt_dic.attention_mask\n",
        "        prompt_len = prompt_ids.shape[1]\n",
        "\n",
        "        if self.num_gpus > 0:\n",
        "            prompt_ids = prompt_ids.to(self.model.device)\n",
        "            prompt_mask = prompt_mask.to(self.model.device)\n",
        "            \n",
        "        source_ids = prompt_ids[:,:-1]\n",
        "        target_ids = prompt_ids[:,1:]\n",
        "        source_mask = prompt_mask[:,:-1]\n",
        "        target_mask = prompt_mask[:,1:]\n",
        "\n",
        "        # allow params to be updated\n",
        "        self.model.train()\n",
        "\n",
        "        for e in range(num_epochs):\n",
        "\n",
        "            outputs = self.model(\n",
        "                input_ids = prompt_ids,\n",
        "                labels = prompt_ids,\n",
        "                attention_mask = prompt_mask,\n",
        "                token_type_ids=None,\n",
        "            )\n",
        "\n",
        "            # used logits and target tokens to calculate the loss\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            print(\"epoch\", e, \"loss\", loss.item())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    \n",
        "    def train(self, train_dataloader, num_epochs = 3):\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "\n",
        "        for batch_idx, samples in enumerate(train_dataloader):\n",
        "\n",
        "          samples = [s.to(self.model.device) for s in samples]\n",
        "\n",
        "          outputs = self.model(\n",
        "              input_ids = samples[0].squeeze(1),\n",
        "              labels = samples[0].squeeze(1),\n",
        "              attention_mask = samples[1].squeeze(1),\n",
        "              token_type_ids=None,\n",
        "          )\n",
        "\n",
        "          # used logits and target tokens to calculate the loss\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        "\n",
        "          # backward pass\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "          self.optimizer.step()\n",
        "\n",
        "        print(\"epoch\", epoch, \"loss\", loss.item())\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    def eval(self, val_list):\n",
        "\n",
        "      for sample in val_list:\n",
        "\n",
        "        print(sample)\n",
        "\n"
      ],
      "metadata": {
        "id": "9N01uvaiX5uO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = BaseAgent(model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEHT8QbMYD90",
        "outputId": "db10eb71-95c3-4fde-ab17-71f84f4c5d8a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.model.device cuda:0\n",
            "num_params 124439808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.eval(val_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH9UiAALuaqc",
        "outputId": "d7b803ac-453c-4eab-bff2-6a26a488bcec"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('i enjoy a late night snack', 'neutral')\n",
            "('I will die if someone tickled me that way ', 'neutral ')\n",
            "('my legs have been swollen for years', 'neutral')\n",
            "('i like my toast slightly burned', 'neutral')\n",
            "(\"I'm having an allergic attack. Help!\", 'emergency')\n",
            "('the tv shows are so violent these days', 'neutral ')\n",
            "('i am finding it harder to breathe today', 'emergency')\n",
            "('the red sox got run over by the yankees', 'neutral')\n",
            "('She had me rolling on the floor laughing', 'neutral')\n",
            "('My cat attacked a bird outside my house', 'neutral ')\n",
            "('i will kill for some nachos', 'neutral ')\n",
            "('i feel out of breath just walking to the kitchen', 'emergency')\n",
            "('my afternoon meal is 3 hours late', 'emergency')\n",
            "('i bumped my head with the sidewalk', 'emergency')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.train(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B97qnopRtXGz",
        "outputId": "7cf0edcf-6279-44a2-b5ed-d78f6169c92b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss 1.1636629104614258\n",
            "epoch 1 loss 0.6864692568778992\n",
            "epoch 2 loss 0.36334311962127686\n"
          ]
        }
      ]
    }
  ]
}